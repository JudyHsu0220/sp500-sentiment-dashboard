# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hqWpib6xNj1SBW4TxPwkwclsN7r8-T8M
"""

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import altair as alt
from wordcloud import WordCloud, STOPWORDS
import ast
from datetime import datetime

# Load data
@st.cache_data

def load_data():
    df = pd.read_csv("merged_sentiment_cleaned_202005_202504.csv")
    df['date'] = pd.to_datetime(df['date'])
    df['nlp_features'] = df['nlp_features'].apply(ast.literal_eval)
    df['tokens'] = df['nlp_features'].apply(lambda x: x.get('tokens', []))
    df['month'] = df['date'].dt.to_period('M')
    return df

df = load_data()

# Sidebar filters
st.sidebar.title("Filters")
filter_mode = st.sidebar.radio("Filter by", ["Date Range", "Single Day"])

if filter_mode == "Date Range":
    start_date = st.sidebar.date_input("Start Date", df['date'].min())
    end_date = st.sidebar.date_input("End Date", df['date'].max())
    mask = (df['date'] >= pd.to_datetime(start_date)) & (df['date'] <= pd.to_datetime(end_date))
else:
    selected_date = st.sidebar.date_input("Select Date", value=pd.to_datetime("2024-12-01"))
    mask = df['date'] == pd.to_datetime(selected_date)

filtered_df = df[mask]

# Tabs
st.title("SP500 News Sentiment Dashboard")
tabs = st.tabs(["Sentiment vs Price", "Mention & Alert", "Word Cloud"])

# 1. SPX500 Sentiment Trendline
with tabs[0]:
    st.header("Sentiment and S&P500 Price Trend")

    price_df = pd.read_csv("sp500_price_202005_202504.csv")
    price_df['date'] = pd.to_datetime(price_df['date'])
    price_df = price_df[price_df['date'].isin(filtered_df['date'].unique())]

    daily_sentiment = filtered_df[filtered_df['related'] == 'S&P 500'].groupby('date')['sentiment'].mean()
    price_series = price_df.set_index('date')['close']

    df_plot = pd.DataFrame({
        'Sentiment': daily_sentiment,
        'Close Price': price_series
    }).dropna()

    base = alt.Chart(df_plot.reset_index()).encode(x='date:T')
    line1 = base.mark_line(color='steelblue').encode(y=alt.Y('Close Price', axis=alt.Axis(title='Price')))
    line2 = base.mark_line(color='orange').encode(y=alt.Y('Sentiment', axis=alt.Axis(title='Sentiment')))
    st.altair_chart(line1 + line2, use_container_width=True)

    st.subheader("Sentiment Stats")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Min Sentiment", round(daily_sentiment.min(), 3))
    col2.metric("Max Sentiment", round(daily_sentiment.max(), 3))
    col3.metric("Mean Sentiment", round(daily_sentiment.mean(), 3))
    col4.metric("Std Dev Sentiment", round(daily_sentiment.std(), 3))

    st.subheader("Price Stats")
    col5, col6, col7, col8 = st.columns(4)
    col5.metric("Min Price", round(price_series.min(), 2))
    col6.metric("Max Price", round(price_series.max(), 2))
    col7.metric("Mean Price", round(price_series.mean(), 2))
    col8.metric("Std Dev Price", round(price_series.std(), 2))

# 2. Company Sentiment Summary
with tabs[1]:
    st.header("Company Mentions and Alerts")
    mention_df = filtered_df[filtered_df['related'] != 'S&P 500']
    summary = mention_df.groupby("related").agg(
        mention_count=('title', 'count'),
        avg_sentiment=('sentiment', 'mean')
    ).reset_index()
    summary['alert'] = summary['avg_sentiment'].apply(lambda x: '❗️' if x < -0.5 else '')

    st.dataframe(summary.sort_values("mention_count", ascending=False))

# 3. Keyword Cloud
with tabs[2]:
    st.header("Sentiment Word Cloud")
    all_tokens = [token.lower() for tokens in filtered_df['tokens'] for token in tokens if isinstance(token, str)]
    stopwords = set(STOPWORDS).union({'the', 'in', 'it', 'of', 'to', 'and', 'as', 'for', 'on', 'is', 'its', 'with', 'are'})
    filtered_tokens = [word for word in all_tokens if word not in stopwords and word.isalpha()]
    word_freq = Counter(filtered_tokens)
    top5_words = word_freq.most_common(5)

    wordcloud = WordCloud(width=1000, height=500, background_color='white', stopwords=stopwords).generate_from_frequencies(word_freq)

    fig, ax = plt.subplots(figsize=(12, 6))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    st.pyplot(fig)

    st.subheader("Top 5 Keywords and Related Headlines")
    for word, _ in top5_words:
        st.markdown(f"**{word.capitalize()}**")
        titles = filtered_df[filtered_df['tokens'].apply(lambda tokens: word in [t.lower() for t in tokens])]['title'].head(5).tolist()
        for t in titles:
            st.markdown(f"- {t}")
