# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hqWpib6xNj1SBW4TxPwkwclsN7r8-T8M
"""

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import altair as alt
from wordcloud import WordCloud, STOPWORDS
import ast
from datetime import datetime
import re
from collections import Counter
import string

# Load data
@st.cache_data

def load_data():
    df = pd.read_csv("merged_sentiment_cleaned_202005_202504.csv")
    df['date'] = pd.to_datetime(df['date'])
    df['nlp_features'] = df['nlp_features'].apply(ast.literal_eval)
    df['tokens'] = df['nlp_features'].apply(lambda x: x.get('tokens', []))
    df['month'] = df['date'].dt.to_period('M')
    return df

df = load_data()

# Sidebar filters
st.sidebar.title("Filters")
filter_mode = st.sidebar.radio("Filter by", ["Date Range", "Single Day"])

if filter_mode == "Date Range":
    start_date = st.sidebar.date_input("Start Date", df['date'].min())
    end_date = st.sidebar.date_input("End Date", df['date'].max())
    mask = (df['date'] >= pd.to_datetime(start_date)) & (df['date'] <= pd.to_datetime(end_date))
else:
    selected_date = st.sidebar.date_input("Select Date", value=pd.to_datetime("2024-12-01"))
    mask = df['date'] == pd.to_datetime(selected_date)

filtered_df = df[mask]

# Tabs
st.title("SP500 News Sentiment Dashboard")
tabs = st.tabs(["Sentiment vs Price", "Mention & Alert", "Word Cloud"])

# 1. SPX500 Sentiment Trendline
with tabs[0]:
    st.header("Sentiment and S&P500 Price Trend")

    # Load and filter price data
    price_df = pd.read_csv("sp500_price_202005_202504.csv")
    price_df['date'] = pd.to_datetime(price_df['date'])

    # Aggregate daily sentiment (S&P 500 only)
    daily_sentiment = filtered_df[filtered_df['related'] == 'S&P 500'].groupby('date')['sentiment'].mean().reset_index()

    # Filter price data to selected date range
    price_df = price_df[price_df['date'].between(filtered_df['date'].min(), filtered_df['date'].max())]

    # Merge sentiment with price on date
    df_plot = pd.merge(daily_sentiment, price_df[['date', 'close']], on='date', how='inner')
    df_plot.rename(columns={'close': 'Close Price', 'sentiment': 'Sentiment'}, inplace=True)

    # If no data, display warning
    if df_plot.empty:
        st.warning("No data available for the selected date range.")
    else:
        # Plot
        base = alt.Chart(df_plot).encode(x='date:T')

        line_price = base.mark_line(color='blue').encode(
            y=alt.Y('Close Price:Q',
                    axis=alt.Axis(title='Price', titleColor='blue'),
                    scale=alt.Scale(domain=[4000, 6500])),
            tooltip=['date:T', alt.Tooltip('Close Price:Q', format=',.2f')]
        )

        line_sentiment = base.mark_line(color='orange').encode(
            y=alt.Y('Sentiment:Q',
                    axis=alt.Axis(title='Sentiment', titleColor='orange'),
                    scale=alt.Scale(domain=[-1.1, 0.5])),
            tooltip=['date:T', alt.Tooltip('Sentiment:Q', format='.3f')]
        )

        chart = alt.layer(line_price, line_sentiment).resolve_scale(y='independent').interactive()
        st.altair_chart(chart, use_container_width=True)

        # Side-by-side Stats
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("Price Stats")
            st.metric("Min Price", round(df_plot['Close Price'].min(), 2))
            st.metric("Max Price", round(df_plot['Close Price'].max(), 2))
            st.metric("Mean Price", round(df_plot['Close Price'].mean(), 2))
            st.metric("Std Dev Price", round(df_plot['Close Price'].std(), 2))
        with col2:
            st.subheader("Sentiment Stats")
            st.metric("Min Sentiment", round(df_plot['Sentiment'].min(), 3))
            st.metric("Max Sentiment", round(df_plot['Sentiment'].max(), 3))
            st.metric("Mean Sentiment", round(df_plot['Sentiment'].mean(), 3))
            st.metric("Std Dev Sentiment", round(df_plot['Sentiment'].std(), 3))

# 2. Company Sentiment Summary
with tabs[1]:
    st.header("Company Mentions and Alerts")
    mention_df = filtered_df[filtered_df['related'] != 'S&P 500']
    summary = mention_df.groupby("related").agg(
        mention_count=('title', 'count'),
        avg_sentiment=('sentiment', 'mean')
    ).reset_index()
    summary['alert'] = summary['avg_sentiment'].apply(lambda x: '❗️' if x < -0.5 else '')

    st.dataframe(summary.sort_values("mention_count", ascending=False))

# 3. Keyword Cloud
with tabs[2]:
    st.header("Sentiment Word Cloud")

    # Join all tokens into lowercase and remove punctuation
    all_tokens_raw = [token.lower() for tokens in filtered_df['tokens'] for token in tokens if isinstance(token, str)]
    cleaned_tokens = [
        re.sub(r'[^\w\s]', '', token) for token in all_tokens_raw
        if token.isalpha()
    ]

    stopwords = set(STOPWORDS).union({
        'the', 'in', 'it', 'of', 'to', 'and', 'as', 'for', 'on', 'is', 'its', 'with', 'are', 'a', 'an', 'this', 'that'
    })

    filtered_tokens = [word for word in cleaned_tokens if word not in stopwords and len(word) > 1]

    wordcloud = WordCloud(
        width=1000, height=500, background_color='white', stopwords=stopwords
    ).generate(" ".join(filtered_tokens))

    fig, ax = plt.subplots(figsize=(12, 6))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    st.pyplot(fig)

    # Top 5 keywords and related headlines
    st.subheader("Top 5 Keywords and Related Headlines")
    top_tokens = Counter(filtered_tokens).most_common(5)

    for word, _ in top_tokens:
        st.markdown(f"**{word}**")
        try:
            pattern = re.compile(rf'\b{re.escape(word)}\b', flags=re.IGNORECASE)
            headlines = filtered_df[filtered_df['title'].str.contains(pattern, na=False)]['title'].head(5).tolist()
            for h in headlines:
                st.markdown(f"- {h}")
        except re.error:
            st.markdown("_Error parsing keyword pattern_")
