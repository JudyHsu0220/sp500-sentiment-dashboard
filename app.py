# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hqWpib6xNj1SBW4TxPwkwclsN7r8-T8M
"""

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import altair as alt
from wordcloud import WordCloud, STOPWORDS
import ast
from datetime import datetime
import re
from collections import Counter

# Load data
@st.cache_data

def load_data():
    df = pd.read_csv("merged_sentiment_cleaned_202005_202504.csv")
    df['date'] = pd.to_datetime(df['date'])
    df['nlp_features'] = df['nlp_features'].apply(ast.literal_eval)
    df['tokens'] = df['nlp_features'].apply(lambda x: x.get('tokens', []))
    df['month'] = df['date'].dt.to_period('M')
    return df

df = load_data()

# Sidebar filters
st.sidebar.title("Filters")
filter_mode = st.sidebar.radio("Filter by", ["Date Range", "Single Day"])

if filter_mode == "Date Range":
    start_date = st.sidebar.date_input("Start Date", df['date'].min())
    end_date = st.sidebar.date_input("End Date", df['date'].max())
    mask = (df['date'] >= pd.to_datetime(start_date)) & (df['date'] <= pd.to_datetime(end_date))
else:
    selected_date = st.sidebar.date_input("Select Date", value=pd.to_datetime("2024-12-01"))
    mask = df['date'] == pd.to_datetime(selected_date)

filtered_df = df[mask]

# Tabs
st.title("SP500 News Sentiment Dashboard")
tabs = st.tabs(["Sentiment vs Price", "Mention & Alert", "Word Cloud"])

# 1. SPX500 Sentiment Trendline
with tabs[0]:
    st.header("Sentiment and S&P500 Price Trend")

    price_df = pd.read_csv("sp500_price_202005_202504.csv")
    price_df['date'] = pd.to_datetime(price_df['date'])
    price_df = price_df[price_df['date'].isin(filtered_df['date'].unique())]

    daily_sentiment = filtered_df[filtered_df['related'] == 'S&P 500'].groupby('date')['sentiment'].mean()
    price_series = price_df.set_index('date')['close']

    aligned_dates = daily_sentiment.index.intersection(price_series.index)

    df_plot = pd.DataFrame({
        'date': aligned_dates,
        'Sentiment': daily_sentiment[aligned_dates].values,
        'Close Price': price_series[aligned_dates].values
    }).dropna()

    base = alt.Chart(df_plot).encode(x='date:T')
    line_price = base.mark_line(color='blue').encode(y=alt.Y('Close Price:Q', axis=alt.Axis(title='Price', titleColor='blue')))
    line_sentiment = base.mark_line(color='orange').encode(y=alt.Y('Sentiment:Q', axis=alt.Axis(title='Sentiment', titleColor='orange')))

    st.altair_chart(alt.layer(line_price, line_sentiment).resolve_scale(y='independent').interactive(), use_container_width=True)

    st.subheader("Sentiment Stats")
    st.metric("Min Sentiment", round(daily_sentiment.min(), 3))
    st.metric("Max Sentiment", round(daily_sentiment.max(), 3))
    st.metric("Mean Sentiment", round(daily_sentiment.mean(), 3))
    st.metric("Std Dev Sentiment", round(daily_sentiment.std(), 3))

    st.subheader("Price Stats")
    st.metric("Min Price", round(price_series.min(), 2))
    st.metric("Max Price", round(price_series.max(), 2))
    st.metric("Mean Price", round(price_series.mean(), 2))
    st.metric("Std Dev Price", round(price_series.std(), 2))

# 2. Company Sentiment Summary
with tabs[1]:
    st.header("Company Mentions and Alerts")
    mention_df = filtered_df[filtered_df['related'] != 'S&P 500']
    summary = mention_df.groupby("related").agg(
        mention_count=('title', 'count'),
        avg_sentiment=('sentiment', 'mean')
    ).reset_index()
    summary['alert'] = summary['avg_sentiment'].apply(lambda x: '❗️' if x < -0.5 else '')

    st.dataframe(summary.sort_values("mention_count", ascending=False))

# 3. Keyword Cloud
with tabs[2]:
    st.header("Sentiment Word Cloud")
    all_tokens = [token.lower() for tokens in filtered_df['tokens'] for token in tokens if isinstance(token, str)]
    stopwords = set(STOPWORDS).union({'the', 'in', 'it', 'of', 'to', 'and', 'as', 'for', 'on', 'is', 'its', 'with', 'are'})

    wordcloud = WordCloud(width=1000, height=500, background_color='white', stopwords=stopwords).generate(" ".join(all_tokens))

    fig, ax = plt.subplots(figsize=(12, 6))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    st.pyplot(fig)

    # Top 5 tokens and related headlines
    st.subheader("Top 5 Keywords and Related Headlines")
    top_tokens = Counter([w for w in all_tokens if w not in stopwords]).most_common(5)
    for word, _ in top_tokens:
        st.markdown(f"**{word}**")
        try:
            safe_word = re.escape(word)
            headlines = filtered_df[filtered_df['title'].str.contains(safe_word, case=False, na=False)].head(5)['title'].tolist()
        except Exception as e:
            headlines = ["Error extracting headlines"]
        for h in headlines:
            st.markdown(f"- {h}")